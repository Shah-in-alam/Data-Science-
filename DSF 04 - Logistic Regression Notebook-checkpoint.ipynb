{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "low_memory=False\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import imblearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.metrics import specificity_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Introduction & Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, classic regression models don't quite work when we're handling categorical data. For this type of data, we need a different type of models called classifiers.\n",
    "\n",
    "Categorical Data is defined as a dataset wherein the dependent variable is of a categorical nature. This means, quite logically, that the dependent variable which we try to understand or predict is not simply continuous. A straightforward example is trying to predict whether a student is male or female based on his/her exam marks. (Let's hope that no clear conclusion is to be drawn in that particular setting.) In that case, our dependent variable can only take two values: male and female. Or more formally, our variable is binary: 1 or 0, true or false. As such, this setting is called a binary classification setting. There are obviously also setting with more than 2 categories, like we will see below.\n",
    "\n",
    "The important part here however, is to realize that a simple regression model will not work for these type of analyses. If gender (0,1) is our dependent variable, and we were to fit a regression model, there will almost certainly be input values which will predict our outcome to be 0,5. How would we need to interpret this? What about when we predict 2 or -10? These are all possible predictions a regression model might make.\n",
    "\n",
    "As such, we need dedicated models to handle categorical data. The first classifier we will see is the Logistic Regression Model. This is a regression model which we restrict from certain prediction values. In other words; we tell the regression model beforehand which the possible values are, and then form the best fitting function to these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Problem Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example problem, we will work with the digits dataset. This is one of the build-in datasets that comes with $sklearn$. It contains pictures of handwritten digits, along with the digit it is supposed to present. In this case,, the number being represented is the dependent variable. This might sound counterintuitive, but it is exactly this property that we are trying to predict. The independent variable is the picture of the handwritten digit. It is this data that we will use to predict which number is being represented. More concretely, since all images have the same amount of pixels with the same coordinates, these are the variables. The value of each of these variables is the tint with which it is filled in.\n",
    "\n",
    "Let's start off by importing the data and taking a look at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "dir(digits)\n",
    "# data\n",
    "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "# Print to show there are 1797 labels (integers from 0â€“9)\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    " plt.subplot(1, 5, index + 1)\n",
    " plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    " plt.title('Training: %i\\n' % label, fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a short look at what the Logistic Regression Model actually does.\n",
    "\n",
    "If we remember the Linear Regression model, we'll remember that it was all build around the linear function: a straight line which just goes on and on. And we fit this line as best as we can within our data. The Logistic Regression Model adapts this function (just like the Polynomial Regression Model does) to a different category of functions. One example of those is the sig function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](https://miro.medium.com/max/1400/1*RqXFpiNGwdiKBWyLJc_E7g.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was the case with our Linear Regression model, the vertical axis represents the dependent variable and the horizontal axis represents the independent variable. As we can see clearly, the sig function doesn't run through to infinity. The maximum value of this function is 1, and the minimum value is 0. This is absolutely perfect to do binary classification.\n",
    "The question now obviously, is how to interpret this. It is clear that all values for t higher than 8 will predict the value 1, and all values under -8 will predict 0. But what for all values between these two? For example; what does the prediction under $t=2$ or $t=0$ mean? When we look at the $sig(t)$ value for $t=0$, we find $0.5$. This value should be interpreted as the probability that the outcome will be 1. Likewise, the prediction for $t=-2$ is that 0 will be achieved with $0.1$ probability and 1 with a $0.9$ probability.\n",
    "\n",
    "The sig function is a good example that we can use for binary classifications. Other functions exist to do this when we have more categories to classify in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Model Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we'll again divide our dataset into a test and a trainingset. This will allow us to evaluate the accuracy of our model later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll fit our model on the data.\n",
    "\n",
    "The first step is just making the model. This is done with several options. These refer to exactly which function we use to fit the data to, and which algorithm we use to fit our data to the chosen function. These options will be further elaborated on in the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=10000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've made our classifier, we'll test if the predictions are any good by predicting the values of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "print(logisticRegr.predict(x_test[0].reshape(1,-1)))\n",
    "print(logisticRegr.predict(x_test[0:10]))\n",
    "predictions = logisticRegr.predict(x_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, we have made a NumPy Array in which the predictions are stored. This however doesn't really tell us anything about whether our predictions are correct. To check this, we'll move over to model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different metrics which we can use for model evaluation.\n",
    "The model evaluation has one clear goal: determining whether our model is any good. How exactly to measure this is rather difficult. In essence, if we make a prediction, we would like it to be correct, all of the time. A good question is how to quantify this.\n",
    "Luckily, we've saved our test set to calculate some stuff!\n",
    "\n",
    "When calculating metrics related to binary classifications we will commonly be using four terms:\n",
    "- $True$ $Positives$ $(TP)$: The amount of labels where the outcome is 1 and the predicted label is 1. In other words, the amount of variables where we **correctly** predicted the postive outcome.\n",
    "- $True$ $Negatives$ $(TN)$: The amount of labels where the outcome is 0 and the predicted label is 0. In other words, the amount of variables where we **correctly** predicted the negative outcome.\n",
    "- $False$ $Positives$ $(FP)$: The amount of labels where the outcome is 0 and the predicted label is 1. In other words, the amount of variables where we **incorrectly** predicted the postive outcome.\n",
    "- $False$ $Negatives$ $(FN)$: The amount of labels where the outcome is 1 and the predicted label is 0. In other words, the amount of variables where we **incorrectly** predicted the negative outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is the first metric we'll take a look at. Accuracy determines how often our classified is correct. We'll make predictions for our test set, and then compare these to the actual values. The $score$ is the measure of accuracy we'll make use of: \n",
    "\n",
    "$$Accuracy = \\frac{\\# \\text{correct predictions}}{\\# \\text{ total observations}}$$\n",
    "\n",
    "When looking at this in the terms we descibed above, the calculation looks like this:\n",
    "\n",
    "$$Accuracy = \\frac{\\text{TP + TN}}{\\text{TP + TN + FP + FN}}$$\n",
    "\n",
    "In Python, we can calculate this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = logisticRegr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, test_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is the most intuitive way to calculate the accuracy, it does require and external function 'accuracy_score' and requires us to manually make some predictions. Instead we can calculate the accuracy of our logistic regression model in a way similar to calculating $R^2$ for linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1: The code above will help us to calculate the score. Try to interpret the value we have gotten. Is our model any good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second metric we'll use is the precision. The precision tries to tell us something about the consistency of our classifier. The question we try to answer is the following: we know how close our classifier is (on average) to the true value, but how large is the variance on the correctness of this prediction? In other words; regardless if my prediction is right or wrong, will it always be the same when a comparable input is given? Unlike accuracy, precision is calculated per class we are trying to predict. This means we have a consistency for our predictions per label.\n",
    "\n",
    "The function for precision looks as follows:\n",
    "\n",
    "$$Precision = \\frac{\\text{TP}}{\\text{TP + FP}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also calculate the global precision using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_score(y_test, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2: Does the precision of our model diminish its accuracy value or not? Explain based on the results we've become."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall and f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above graph, you will notice three other scores. Today we will be exploring two more of them: Recall and F1-Score, as well as the sister of Recall: Specificity.\n",
    "\n",
    "$Recall$, also called the $True$ $Positive$ $Rate$ (TPR) calculates how well the model identifies positive instances. This is useful when you want to make sure there are as few False Negatives as possible. For example, when trying to predict someone has cancer you do not want to incorrectly predict someone has no cancer. It is more important to correctly identify the people who do not have cancer, and perform further tests on the ones you are not certain about. This results in the following formula:\n",
    "\n",
    "$$Recall = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
    "\n",
    "In python, you can generate the global Recall score as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(y_test, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sister of recall is called $Specificity$, or the $True$ $Negative$ $Rate$ (TNR). This metric calculates how well the model identifies negative instances. This is useful when you want a model where there are few False Positives. For example, when detecting fraud you do not want to falsely accuse someone. It is more more important to correctly identify people who do commit fraud, than those who do not. Have a look at the formula.\n",
    "\n",
    "$$Specificity = \\frac{\\text{TN}}{\\text{TN + FP}}$$\n",
    "\n",
    "Once again, you can easily calculate the global Specificity score in python as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(specificity_score(y_test, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we have the $F1 Score$. This score brings a balance between Recall and Specificity, taking into account unbalanced classes. The formula gets a bit more complicated as follows:\n",
    "\n",
    "$$F1 Score = 2 * \\frac{\\text{Precision x Recall}}{\\text{Precision + Recall}}$$\n",
    "\n",
    "When writing this out and simplifying it, we get the following formula:\n",
    "\n",
    "$$F1 Score = 2 * \\frac{\\text{TP}}{\\text{TP + FP + FN}}$$\n",
    "\n",
    "Once again, you can easily calculate the global F1 Score in python as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to the above metrics, it might sometimes be interesting to provide graphical, more intuitive metrics. A first example of this is the confusion matrix. The confusion matrix shows for each label in the true data, each prediction that is made. We hope to see a diagonal here with very high values, and hope so see as much zeroes as possible everywhere else. As this would mean all predictions be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though perfectly readable, this is not the type of \"intuitive graphical representation\" you might want to present to illustrate your conclusions. Luckily, this is very handy to mark-up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3: for which metric we discussed above, is the Confusion Matrix a graphical representation? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Illustrations\n",
    "\n",
    "Additional illustrations do exist (such as the ROC), but these are not always interesting nor possible for multiclass analysis. It might however be interesting to think about one illustration that will convince your audience you do know what you're talking about. For this, make question 4.\n",
    "\n",
    "##### Question 4: Go back and take a look at section 3.2, and the illustration we provided there. Try and adapt the code to represent 10 data points, and also include the predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1: See section 4.4\n",
    "\n",
    "##### Question 2: See section 4.4\n",
    "\n",
    "##### Question 3: See section 4.4\n",
    "\n",
    "##### Question 4: See section 4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5: Go back to section 3.3.2 and remember that we could include different options into our model. In this question we take a look at the \"solvers\", and their efficiency. A solver is an algorithm that is used to estimate and thus fit our desired functions. The option max_iter gives a maximum to how many iterations the algorithm may make (think: loops). Compare the precision and accuracy for the logistic regression model using different algorithms (lbfgs, saga, newton-cg) and different levels of max_iteration. Report on which algorithm achieves a desired level of accuracy and precision in the most efficient way (the least number of iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
